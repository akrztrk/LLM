{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12\n",
      "CUDA available: True\n",
      "GPU: NVIDIA L4\n",
      "CWD: /content/drive/MyDrive/LLM/notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME = /content/drive/MyDrive/hf_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HF_CACHE = \"/content/drive/MyDrive/hf_cache\"\n",
    "Path(HF_CACHE).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = HF_CACHE\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n",
    "\n",
    "print(\"HF_HOME =\", os.environ[\"HF_HOME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages installed\n"
     ]
    }
   ],
   "source": [
    "%pip -q install -U transformers datasets accelerate peft bitsandbytes sentencepiece huggingface_hub\n",
    "print(\"packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08448e0c1bc74dc0a95631b518586ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OK: BramVanroy/GEITje-7B-ultra\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"BramVanroy/GEITje-7B-ultra\"  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,  # safer for Colab L4 memory\n",
    ")\n",
    "\n",
    "print(\"MODEL OK:\", model_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct Dutch sentence: Ik heb gisteren naar de winkel gegaan.\n",
      "\n",
      "Mistake: naar winkel gaan.\n",
      "Explanation: In Dutch, \"naar winkel gaan\" is \"naar de winkel gaan\".\n",
      "\n",
      "Dutch examples:\n",
      "1. Ik ga naar de supermarkt.\n",
      "2. Ik ga naar de boekwinkel.\n",
      "\n",
      "This is an example of how to reply to a Dutch language tutoring question. The tutor will provide a correct Dutch sentence and explain the mistake, along with two short Dutch examples.</s>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "prompt = (\n",
    "    \"You are a Dutch language tutor.\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"- Reply in simple English.\\n\"\n",
    "    \"- Correct the Dutch sentence.\\n\"\n",
    "    \"- Explain the mistake briefly.\\n\"\n",
    "    \"- Give 2 short Dutch examples.\\n\\n\"\n",
    "    \"Student sentence: Ik heb gisteren naar winkel gaan.\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,\n",
    "        top_p=0.9,\n",
    "        streamer=streamer,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FORMAT = \"\"\"\n",
    "Correct sentence:\n",
    "Ik ben gisteren naar de winkel gegaan.\n",
    "\n",
    "Explanation (simple English):\n",
    "In Dutch, past actions with \"gaan\" use \"zijn\" as the auxiliary verb.\n",
    "\"Gaan\" is a movement verb, so we say \"ik ben gegaan\", not \"ik heb gegaan\".\n",
    "\n",
    "Examples:\n",
    "- Ik ben gisteren naar huis gegaan.\n",
    "- Zij is vorige week naar school gegaan.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /content/drive/MyDrive/LLM/data/dutch_tutor/train_v0.jsonl\n",
      "Rows: 10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"/content/drive/MyDrive/LLM/data/dutch_tutor/train_v0.jsonl\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a Dutch language tutor. \"\n",
    "    \"Reply in simple English. \"\n",
    "    \"Correct the Dutch sentence, explain briefly, then give 2 short Dutch examples.\"\n",
    ")\n",
    "\n",
    "samples = [\n",
    "    (\"Ik heb gisteren naar winkel gaan.\",\n",
    "     \"Correct sentence:\\nIk ben gisteren naar de winkel gegaan.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nFor movement verbs like 'gaan', Dutch uses 'zijn' in the past: 'ik ben gegaan'.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ben gisteren naar huis gegaan.\\n- Zij is vorige week naar school gegaan.\\n\"),\n",
    "    (\"Hij hebben een auto.\",\n",
    "     \"Correct sentence:\\nHij heeft een auto.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nWith 'hij/zij/het' you use 'heeft', not 'hebben'.\\n\\n\"\n",
    "     \"Examples:\\n- Hij heeft een fiets.\\n- Zij heeft een hond.\\n\"),\n",
    "    (\"Wij is blij.\",\n",
    "     \"Correct sentence:\\nWij zijn blij.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nWith 'wij' you use 'zijn', not 'is'.\\n\\n\"\n",
    "     \"Examples:\\n- Wij zijn thuis.\\n- Wij zijn moe.\\n\"),\n",
    "    (\"Ik woon in Nederland sinds twee jaar.\",\n",
    "     \"Correct sentence:\\nIk woon al twee jaar in Nederland.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nUse 'al' to say how long something has been true up to now.\\n\\n\"\n",
    "     \"Examples:\\n- Ik werk al drie maanden hier.\\n- Zij leert al een jaar Nederlands.\\n\"),\n",
    "    (\"Morgen ik ga naar werk.\",\n",
    "     \"Correct sentence:\\nMorgen ga ik naar het werk.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nIn Dutch, the verb usually comes in position 2.\\n\\n\"\n",
    "     \"Examples:\\n- Vandaag ga ik naar de winkel.\\n- Morgen kom ik later.\\n\"),\n",
    "    (\"Ik kan niet vind mijn sleutel.\",\n",
    "     \"Correct sentence:\\nIk kan mijn sleutel niet vinden.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nThe infinitive goes to the end, and 'niet' comes before it.\\n\\n\"\n",
    "     \"Examples:\\n- Ik kan dat niet begrijpen.\\n- Hij kan morgen niet komen.\\n\"),\n",
    "    (\"Zij gaat naar school met de fiets.\",\n",
    "     \"Correct sentence:\\nZij gaat met de fiets naar school.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nBoth are understandable, but placing 'met de fiets' earlier is more natural.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ga met de trein naar Amsterdam.\\n- We gaan met de auto naar huis.\\n\"),\n",
    "    (\"Ik heb honger, ik eet een broodje gisteren.\",\n",
    "     \"Correct sentence:\\nIk had gisteren honger, dus ik heb een broodje gegeten.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nUse past tense for 'yesterday' and a completed action: 'heb gegeten'.\\n\\n\"\n",
    "     \"Examples:\\n- Ik heb gisteren pasta gegeten.\\n- Hij heeft vorige week pizza gegeten.\\n\"),\n",
    "    (\"Waar is de station?\",\n",
    "     \"Correct sentence:\\nWaar is het station?\\n\\n\"\n",
    "     \"Explanation (simple English):\\n'Het station' is a 'het' word, so use 'het'.\\n\\n\"\n",
    "     \"Examples:\\n- Waar is het toilet?\\n- Waar is het museum?\\n\"),\n",
    "    (\"Ik wil een afspraak maken bij dokter.\",\n",
    "     \"Correct sentence:\\nIk wil een afspraak maken bij de dokter.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nUse 'de dokter' with the article.\\n\\n\"\n",
    "     \"Examples:\\n- Ik wil een afspraak maken bij de tandarts.\\n- Ik heb een afspraak bij de huisarts.\\n\"),\n",
    "]\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for user_text, assistant_text in samples:\n",
    "        row = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": f\"Student sentence: {user_text}\"},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_text},\n",
    "            ]\n",
    "        }\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Wrote:\", out_path)\n",
    "print(\"Rows:\", len(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c2614340944e91afdac361251ae664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10\n",
      "{'messages': [{'role': 'system', 'content': 'You are a Dutch language tutor. Reply in simple English. Correct the Dutch sentence, explain briefly, then give 2 short Dutch examples.'}, {'role': 'user', 'content': 'Student sentence: Ik heb gisteren naar winkel gaan.'}, {'role': 'assistant', 'content': \"Correct sentence:\\nIk ben gisteren naar de winkel gegaan.\\n\\nExplanation (simple English):\\nFor movement verbs like 'gaan', Dutch uses 'zijn' in the past: 'ik ben gegaan'.\\n\\nExamples:\\n- Ik ben gisteren naar huis gegaan.\\n- Zij is vorige week naar school gegaan.\\n\"}]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/LLM/data/dutch_tutor/train_v0.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(\"Rows:\", len(ds))\n",
    "print(ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QLoRA configs ready\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import LoraConfig\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# 4-bit quantization config (QLoRA)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "print(\"QLoRA configs ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584e7b2d411e43eeba404a120e8ac73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 4-bit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"BramVanroy/GEITje-7B-ultra\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "print(\"Model loaded in 4-bit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.0470\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.576900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DONE\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/LLM/models/dutch_tutor_lora_v0\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    save_steps=10,\n",
    "    report_to=[],\n",
    "\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    gradient_checkpointing=False,  \n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=ds,\n",
    "    args=args,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"TRAIN DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /content/drive/MyDrive/LLM/models/dutch_tutor_lora_v0/adapter\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"/content/drive/MyDrive/LLM/models/dutch_tutor_lora_v0/adapter\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"SAVED:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ik heb gisteren naar winkel gaan. (correct)\n",
      "\n",
      "Mistake:\n",
      "\"naar winkel gaan\" is correct Dutch.\n",
      "\n",
      "Examples:\n",
      "1. Ik ga naar de supermarkt.\n",
      "2. Ik ga naar de boekwinkel.\n",
      "\n",
      "Explanation:\n",
      "In Dutch, \"naar winkel gaan\" is a continuous action (gaan) with an infinitive (naar winkel). This is a common construction in Dutch.\n",
      "\n",
      "In English, \"to go to\" is a preposition that is used with a noun, in this case \"winkel\". In Dutch, we use \"naar\" with a noun, and \"gaan\" with an infinitive.\n",
      "\n",
      "In English, \"to\" is optional, but in Dutch it is not. \"Naar\" is the preposition that we use\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "prompt = (\n",
    "    \"You are a Dutch language tutor.\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"- Reply in simple English.\\n\"\n",
    "    \"- Correct the Dutch sentence.\\n\"\n",
    "    \"- Explain the mistake briefly.\\n\"\n",
    "    \"- Give 2 short Dutch examples.\\n\\n\"\n",
    "    \"Student sentence: Ik heb gisteren naar winkel gaan.\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,\n",
    "        top_p=0.9,\n",
    "        streamer=streamer,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset written to: /content/drive/MyDrive/LLM/data/dutch_tutor/train_v1.jsonl\n",
      "Added samples: 10\n",
      "Total rows: 20\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"/content/drive/MyDrive/LLM/data/dutch_tutor/train_v1.jsonl\")\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a Dutch language tutor. \"\n",
    "    \"Reply in simple English. \"\n",
    "    \"Correct the Dutch sentence, explain briefly, then give 2 short Dutch examples.\"\n",
    ")\n",
    "\n",
    "new_samples = [\n",
    "    (\"Ik heb gisteren naar winkel gaan.\",\n",
    "     \"Correct sentence:\\nIk ben gisteren naar de winkel gegaan.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nWith movement verbs like 'gaan', Dutch uses 'zijn' in the past. Also, 'winkel' needs the article 'de'.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ben gisteren naar huis gegaan.\\n- Zij is vorige week naar de supermarkt gegaan.\\n\"),\n",
    "\n",
    "    (\"Hij heb naar huis gegaan.\",\n",
    "     \"Correct sentence:\\nHij is naar huis gegaan.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nMovement verbs use 'zijn' in the past, not 'hebben'.\\n\\n\"\n",
    "     \"Examples:\\n- Hij is naar school gegaan.\\n- Hij is laat naar huis gegaan.\\n\"),\n",
    "\n",
    "    (\"Wij hebben naar Amsterdam gegaan.\",\n",
    "     \"Correct sentence:\\nWij zijn naar Amsterdam gegaan.\\n\\n\"\n",
    "     \"Explanation (simple English):\\n'Gaan' is a movement verb, so we use 'zijn'.\\n\\n\"\n",
    "     \"Examples:\\n- Wij zijn naar Utrecht gegaan.\\n- Wij zijn samen gegaan.\\n\"),\n",
    "\n",
    "    (\"Ik ben naar winkel gegaan.\",\n",
    "     \"Correct sentence:\\nIk ben naar de winkel gegaan.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nSingular nouns usually need an article like 'de' or 'het'.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ga naar de bakker.\\n- Ik ga naar de supermarkt.\\n\"),\n",
    "\n",
    "    (\"Zij is gisteren werken gegaan.\",\n",
    "     \"Correct sentence:\\nZij is gisteren gaan werken.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nWhen two verbs are together, the infinitive usually comes at the end.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ben gaan slapen.\\n- Hij is gaan studeren.\\n\"),\n",
    "\n",
    "    (\"Ik heb naar huis gefietst.\",\n",
    "     \"Correct sentence:\\nIk ben naar huis gefietst.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nMovement verbs like 'fietsen' also use 'zijn' in the past.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ben naar school gefietst.\\n- Zij is snel naar huis gefietst.\\n\"),\n",
    "\n",
    "    (\"Hij heeft naar kantoor gereden.\",\n",
    "     \"Correct sentence:\\nHij is naar kantoor gereden.\\n\\n\"\n",
    "     \"Explanation (simple English):\\n'Rijden' is a movement verb, so the auxiliary verb is 'zijn'.\\n\\n\"\n",
    "     \"Examples:\\n- Hij is naar het werk gereden.\\n- Wij zijn samen gereden.\\n\"),\n",
    "\n",
    "    (\"Ik heb gisteren gekomen.\",\n",
    "     \"Correct sentence:\\nIk ben gisteren gekomen.\\n\\n\"\n",
    "     \"Explanation (simple English):\\n'Komen' always uses 'zijn' in the past.\\n\\n\"\n",
    "     \"Examples:\\n- Zij is vroeg gekomen.\\n- Hij is later gekomen.\\n\"),\n",
    "\n",
    "    (\"Wij hebben thuis gebleven.\",\n",
    "     \"Correct sentence:\\nWij zijn thuis gebleven.\\n\\n\"\n",
    "     \"Explanation (simple English):\\n'Blijven' is also a movement/state-change verb and uses 'zijn'.\\n\\n\"\n",
    "     \"Examples:\\n- Ik ben thuis gebleven.\\n- Zij is een week gebleven.\\n\"),\n",
    "\n",
    "    (\"Ik ga naar winkel morgen.\",\n",
    "     \"Correct sentence:\\nMorgen ga ik naar de winkel.\\n\\n\"\n",
    "     \"Explanation (simple English):\\nIn Dutch, the verb comes in position 2.\\n\\n\"\n",
    "     \"Examples:\\n- Vandaag ga ik werken.\\n- Morgen ga ik sporten.\\n\"),\n",
    "]\n",
    "\n",
    "# Append to existing dataset\n",
    "with open(\"/content/drive/MyDrive/LLM/data/dutch_tutor/train_v0.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    existing = f.readlines()\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for line in existing:\n",
    "        f.write(line)\n",
    "    for user_text, assistant_text in new_samples:\n",
    "        row = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM},\n",
    "                {\"role\": \"user\", \"content\": f\"Student sentence: {user_text}\"},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_text},\n",
    "            ]\n",
    "        }\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"New dataset written to:\", out_path)\n",
    "print(\"Added samples:\", len(new_samples))\n",
    "print(\"Total rows:\", len(existing) + len(new_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6223bb383643b9a6478e96580d5e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9bdf8637f147f8a0609fea0e25b377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6178c38360eb4d58af95f277f225487e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f5400c2b3e45b78234763c2ed0cf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.917800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.901800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.855800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.639500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.574800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.548300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN V1 DONE\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from peft import get_peft_model\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# 1) Load the new dataset\n",
    "ds_v1 = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/LLM/data/dutch_tutor/train_v1.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "print(\"Rows:\", len(ds_v1))\n",
    "\n",
    "# 2) Reload base model in 4-bit (fresh) + attach LoRA\n",
    "model_id = \"BramVanroy/GEITje-7B-ultra\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "model_v1 = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# 3) Train (use bf16, fp16 off)\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/LLM/models/dutch_tutor_lora_v1\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=1,\n",
    "    save_steps=20,\n",
    "    report_to=[],\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model_v1,\n",
    "    train_dataset=ds_v1,\n",
    "    args=args,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"TRAIN V1 DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /content/drive/MyDrive/LLM/models/dutch_tutor_lora_v1/adapter\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"/content/drive/MyDrive/LLM/models/dutch_tutor_lora_v1/adapter\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_v1.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"SAVED:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct sentence:\n",
      "Ik ben gisteren naar de winkel gegaan.\n",
      "\n",
      "Explanation:\n",
      "- 'Ik heb' is not correct.\n",
      "- 'Ik ben' is correct.\n",
      "\n",
      "Examples:\n",
      "- Ik ben naar de winkel gegaan.\n",
      "- Ik ben naar de bioscoop gegaan.\n",
      "\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "prompt = (\n",
    "    \"You are a Dutch language tutor.\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"- Reply in simple English.\\n\"\n",
    "    \"- Correct the Dutch sentence.\\n\"\n",
    "    \"- Explain the mistake briefly.\\n\"\n",
    "    \"- Give 2 short Dutch examples.\\n\\n\"\n",
    "    \"Student sentence: Ik heb gisteren naar winkel gaan.\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model_v1.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model_v1.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=160,\n",
    "        do_sample=True,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        streamer=streamer,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMh6hOZFRhC2gOms3xtFdkH",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
